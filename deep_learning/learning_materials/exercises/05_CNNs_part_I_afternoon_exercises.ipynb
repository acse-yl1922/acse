{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMxqeeehFArhwtxs9nfWGbD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["<img src=\"https://drive.google.com/uc?id=1dFgNX9iQUfmBOdmUN2-H8rPxL3SLXmxn\" width=\"400\"/>\n","\n","\n","---\n"],"metadata":{"id":"9YehS8enAmDn"}},{"cell_type":"markdown","source":["# **CNNs: convolutional neural networks**\n","\n","\n","#### **Morning contents/agenda**\n","\n","1. What are convolutions?\n","\n","2. How do we use them? (`Torch` layer operations)\n","\n","3. Visual roadmap of a CNN\n","\n","4. Implementation of a network similar to LeNet5\n","\n","5. Training our LeNet5-like network on `FasionMNIST`\n","\n","\n","#### **Learning outcomes**\n","\n","1. Have a clear idea of how convolutions work\n","\n","2. Understand the parameters trained in a CNN\n","\n","3. CNN architectures and combinations with other types of layers\n","\n","4. Implementation of  asimple CNN in `PyTorch`\n","\n","<br>\n","\n","#### **Afternoon contents/agenda**\n","\n","1. Dropout and batch normalisation\n","\n","2. Training with data augmentation\n","\n","#### **Learning outcomes**\n","\n","1. Implement dropout and batchnorm layers in `PyTorch`\n","\n","2. Perform data augmentations and understand its effects\n","\n","\n","<br/>\n","\n","---\n","\n","<br/>"],"metadata":{"id":"JgF-9hCV7x33"}},{"cell_type":"code","source":["!pip install pycm livelossplot\n","!pip install torchsummary \n","%pylab inline\n","\n","from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import StratifiedShuffleSplit\n","\n","from livelossplot import PlotLosses\n","from pycm import *\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import TensorDataset, DataLoader\n","import torchvision.datasets\n","import torchvision.transforms as transforms\n","from torchvision.datasets import MNIST\n","from torchsummary import summary"],"metadata":{"id":"_kYki018eTFJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def set_seed(seed):\n","    \"\"\"\n","    Use this to set ALL the random seeds to a fixed value and take out any randomness from cuda kernels\n","    \"\"\"\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","\n","    torch.backends.cudnn.benchmark = False  ##uses the inbuilt cudnn auto-tuner to find the fastest convolution algorithms. -\n","    torch.backends.cudnn.enabled   = False\n","\n","    return True\n","\n","device = 'cpu'\n","if torch.cuda.device_count() > 0 and torch.cuda.is_available():\n","    print(\"Cuda installed! Running on GPU!\")\n","    device = 'cuda'\n","else:\n","    print(\"No GPU available!\")"],"metadata":{"id":"LI8sNA9feT3H"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 1. Dropout and batch normalisation\n","\n","Modify your LeNet-5 network to include dropout and batch normalisation\n","\n","Only run the final training (with all the training data, no splits) with all the data and compare the accuracy and loss values with the network we trained this morning without dropout or batch normalisation."],"metadata":{"id":"8CRenRypN6yH"}},{"cell_type":"code","source":["### modify the network below to add one bathnorm layer and one dropout layer (play with their positions in the network)\n","\n","class LeNet5(nn.Module):\n","  def __init__(self):\n","    super(LeNet5, self).__init__()\n","    self.c1 = nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=2) # define a 2D convolutional layer\n","    self.s2 = nn.MaxPool2d(kernel_size=2, stride=2)               # define a maxpool layer\n","    self.c3 = nn.Conv2d(6, 16, kernel_size=5, stride=1)           # new 2D convolutional layer\n","    self.s4 = nn.MaxPool2d(kernel_size=2, stride=2)               # another maxpool layer\n","    self.c5 = nn.Linear(16*5*5, 120)                              # first linear layer\n","    self.f6 = nn.Linear(120, 84)                                  # second linear layer\n","    self.output = nn.Linear(84, 10)                               # final output layer\n","    self.act = nn.ReLU()                                          # activation function\n","    \n","  def forward(self, x):\n","    x = self.act(self.c1(x))                                      # activate pass through the first layer\n","    x = self.act(self.s2(x))                                      # activate pass through the second layer\n","    x = self.act(self.c3(x))                                      # activate pass through the third layer\n","    x = self.act(self.s4(x))                                      # activate pass through the fourth layer\n","    x = x.view(-1, x.size(1)*x.size(2)*x.size(3))                 # flatten (return a \"flattened\" view of the 3d tensor as inputs for the fully connected layer)\n","    x = self.act(self.c5(x))                                      # activate pass through fifth layer\n","    x = self.act(self.f6(x))                                      # activate pass through last layer\n","    return self.output(x)                                         # return output\n","  \n","x = torch.randn((1, 1, 28, 28))\n","model = LeNet5()\n","y = model(x)\n","print(y)\n","print(model)"],"metadata":{"id":"_DQSI5mVOHqi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mnist_train = ### download MNIST train\n","mnist_test =  ### download MNIST test"],"metadata":{"id":"Ba3ZEvLZND8k"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Instantiate and create a ```StratifiedShuffleSplit``` using sklearn.\n","1. Create a ```sklearn.model_selection.StratifiedShuffleSplit``` object with 1-split and a test-size of 10%.\n","2. Get the training and validation indices from the shuffel-split"],"metadata":{"id":"Lndb4nqhOFcF"}},{"cell_type":"code","source":["# split the data\n","shuffler = ### your code goes here \n","indices =  ### your code goes here"],"metadata":{"id":"ca114gl7NTyb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Standardise and split the MNIST dataset:\n","\n","The original MNIST data is given in gray-scale values between 0 and 255.\n","You will need to write a normalisation method that takes in a ```torch.Tensor``` and performs normalisation.\n","The mean of MNIST is 0.1307 and it's standard deviation is 0.3081 (after division by 255)."],"metadata":{"id":"lSXLG4ksOUxR"}},{"cell_type":"code","source":["def apply_standardization(X): # define an standardisation function\n","  ### your code goes here\n","  return X"],"metadata":{"id":"pzaVKkcaORaS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# standardise the data\n","X_train, y_train = ### your code goes here\n","X_val, y_val =     ### your code goes here\n","X_test, y_test =   ### your code goes here"],"metadata":{"id":"NpRWm3ByOUMq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Instantiate a ```torch.utils.data.TensorDataset``` for training, validation and test data:\n","\n","Remember that we use TensorDataset to be able to operate on the dataset without having to load it all in memory.\n","\n","And remember that torch likes all categorical data to be in a ```.long()``` format."],"metadata":{"id":"bDeXtYyxPhpr"}},{"cell_type":"code","source":["# create the TensorDatasets containing mnist_train, mnist_validate, and mnist_test\n","mnist_train =    ### your code goes here\n","mnist_validate = ### your code goes here\n","mnist_test =     ### your code goes here"],"metadata":{"id":"aiNJegkdPcZw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Provided Train, Validation and Evaluate Functions\n","\n","There is an error in these functions. Can you spot it?"],"metadata":{"id":"t4v_90F-XALf"}},{"cell_type":"code","source":["def train(model, optimizer, criterion, data_loader):\n","    ### set the model to train\n","    train_loss, train_accuracy = ### initialise the loss and the accuracy\n","    for X, y in data_loader:\n","        ### your code goes here\n","        \n","    return  ### your code goes here\n","\n","  \n","def validate(model, criterion, data_loader):\n","    ### set the model to evaluate\n","    validation_loss, validation_accuracy = ### initialise the loss and the accuracy\n","    for X, y in data_loader:\n","           ### your code goes here\n","\n","            \n","    return ### your code goes here\n","\n","  \n","def evaluate(model, data_loader):\n","    ### set the model to evaluate\n","    ys, y_preds = [], []\n","    for X, y in data_loader:\n","            ### your code goes here\n","\n","            \n","    return np.concatenate(y_preds, 0),  np.concatenate(ys, 0)"],"metadata":{"id":"eF6ACgGlPuJg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Set the hyperparameters of your model\n","\n","- Seed: 42\n","- learning rate: 1e-2\n","- Optimizer: SGD\n","- momentum: 0.9\n","- Number of Epochs: 30\n","- Batchsize: 64\n","- Test Batch Size (no effect on training apart from time): 1000\n","- Shuffle the training set every epoch: Yes"],"metadata":{"id":"alGiYGXzYDqY"}},{"cell_type":"code","source":["seed = \n","lr = \n","momentum = \n","batch_size = \n","test_batch_size = \n","n_epochs = "],"metadata":{"id":"u7UXTrQTX9-i"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Perform the training of the network and validation\n","\n","- Instantiate our model, optimizer and loss function\n","- Set the random number generator seed using ```set_seed``` to make everything reproducible.\n","- Use a sensible loss (criterion) for the multi-class classification problem."],"metadata":{"id":"xmSrFBryYHNG"}},{"cell_type":"code","source":["def train_model(momentum):\n","  set_seed(seed)\n","  model = ### your code goes here\n","\n","  optimizer = ### your code goes here\n","  criterion = ### your code goes here\n","  \n","  train_loader = ### your code goes here\n","  validation_loader = ### your code goes here\n","  test_loader = ### your code goes here\n","  \n","  liveloss = PlotLosses()\n","  for epoch in range(30):\n","      logs = {}\n","      train_loss, train_accuracy = train(model, optimizer, criterion, train_loader)\n","\n","      logs['' + 'log loss'] = train_loss.item()\n","      logs['' + 'accuracy'] = train_accuracy.item()\n","\n","      validation_loss, validation_accuracy = validate(model, criterion, validation_loader)\n","      logs['val_' + 'log loss'] = validation_loss.item()\n","      logs['val_' + 'accuracy'] = validation_accuracy.item()\n","\n","      liveloss.update(logs)\n","      liveloss.draw()\n","      \n","  return model\n","\n","model = ### train the model using momentum = 0.5"],"metadata":{"id":"kJ6Xr5acYvsi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Use the evaluation function defined above to make predictions.\n","\n","This method performs the same as validate but doesn't report losses, but simply returns all predictions on a given dataset (training, validation, test-set)"],"metadata":{"id":"hrBcU1Edcwij"}},{"cell_type":"code","source":["validation_loader = DataLoader(mnist_validate, batch_size=test_batch_size, shuffle=False, num_workers=0) # create a validation_loader\n","y_pred, y_gt = evaluate(model, validation_loader) # generate predictions and ground truths by evaluating the model"],"metadata":{"id":"nWkXr0EvY0JR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import ConfusionMatrixDisplay\n","\n","fig, ax = plt.subplots(figsize=(6,6))\n","ConfusionMatrixDisplay.from_predictions(y_gt, y_pred, ax=ax, colorbar=False, cmap='bone_r')\n","plt.show()"],"metadata":{"id":"fWavLY-Ic2Cs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<br>\n","\n","---\n","\n","<br>"],"metadata":{"id":"poGNyBmUYYXL"}},{"cell_type":"markdown","source":["## 2. Training with data augmentation\n","\n","\n","Reminder of Custom Datasets and Transforms (from Debbie's lectures):\n","\n","Pytorch allows us to simply extend the available Datasets to more custom functionality. Here we provide an example of such a custom dataset class. You can see that there are 3 functions we need to implement:\n","\n","- init(args, *kwargs): this will handle everything prior to actually using the dataset\n","- len(self): returns the length of the dataset i.e. the number of data items\n","- getitem(self, idx): this method takes an index of a specific data item and returns that item:\n","  - you can do whatever you want in these functions: apply transforms, normalize data, perform another computation, etc.\n","  - here we also have the functionality to apply a set of [torchvision.transforms](https://pytorch.org/tutorials/beginner/data_loading_tutorial.\n","\n"],"metadata":{"id":"S1a8D_LPYbSB"}},{"cell_type":"markdown","source":["Define a custom image TensorDataset:"],"metadata":{"id":"R6NUgmanbdxA"}},{"cell_type":"code","source":["from torch.utils.data import Dataset \n","\n","class CustomImageTensorDataset(Dataset):\n","    def __init__(self, data, targets, transform=None):\n","        \"\"\"\n","        Args:\n","            data (Tensor): A tensor containing the data e.g. images\n","            targets (Tensor): A tensor containing all the labels\n","            transform (callable, optional): Optional transform to be applied\n","                on a sample.\n","        \"\"\"\n","        self.data = data\n","        self.targets = targets\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        sample, label = self.data[idx], self.targets[idx]\n","        sample = sample.view(1, 28, 28).float()/255.\n","        if self.transform:\n","            sample = self.transform(sample)\n","\n","        return sample, label"],"metadata":{"id":"y_ktXAzfWOwX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E77N_2_sIf7F"},"source":["### Transforms\n","\n","Transforms can be used to perform manipulation of individual data prior to passing the data to our models.\n","This is useful for:\n"," - Data-augmentation i.e. creating slightly modified instance of the data we have while preserving their labels.\n"," - Data Preprocessing: Such as Normalization, Histogram Equalization \n"," - Transforming Targets: You may have complex labels that should change together with changes in the preprocessing of the images\n"," \n"," Pytorch and especially torchvision provides a [number of transforms](https://pytorch.org/docs/stable/torchvision/index.html) for you to use!\n"," A nice tutorial on custom dataloaders and transforms can be found [here](https://github.com/utkuozbulak/pytorch-custom-dataset-examples).\n"," \n"," The (probably) most state-of-the-art library for image augmentation is [albumentations](https://github.com/albu/albumentations) which has been successfully applied in winning kaggle competitions.\n"," "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EquGHuKiIf7G"},"outputs":[],"source":["from torchvision.transforms import Compose, ToTensor, Normalize, RandomRotation, ToPILImage\n","\n","\n","#Often we will want to apply more transformations at training time than test time, therefore here we have two different ones\n","train_transform = Compose([\n","    ToPILImage(),\n","    ### add a random rotation of 10 degrees here\n","    ToTensor(),\n","    Normalize(mean=[0.1307], std=[0.3081]), \n","]) ## Compose different transforms together. PIL is Python Imaging Library useful for opening, manipulating, and saving many different image file formats.\n","\n","#In Validation and Test Mode we only want to normalize our images, because they are already tensors\n","validation_test_transform = Compose([ ### if you think it is adequate, add a random rotation here as well\n","    Normalize(mean=[0.1307], std=[0.3081])\n","])"]},{"cell_type":"markdown","metadata":{"id":"Yo_-JHavIf7G"},"source":["### `code along` Training with data augmentation\n","\n","- Instantiate a ```CustomImageTensorDataset``` with data from the MNIST dataset\n","- Provide the training and validation and testing datasets with the right transforms\n","- Train LeNet-5 with data-augmentation on a validation set, then train on the full training set and report accuracies. Did you improve the model?\n","\n","\n","\n","\n","\n","\n","#### Create the ```CustomImageTensorDataset```:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wh2m9wJyIf7H"},"outputs":[],"source":["mnist_train = MNIST(\"./\", download=True, train=True)   # download mnist\n","X_train, y_train = mnist_train.data[indices[0]], mnist_train.targets[indices[0]]    # split in train and validation\n","X_val, y_val = mnist_train.data[indices[1]], mnist_train.targets[indices[1]]\n","\n","custom_mnist_train = CustomImageTensorDataset(X_train, y_train, transform=train_transform)     # create train custom dataset\n","mnist_validation = CustomImageTensorDataset(X_val, y_val, transform=validation_test_transform) # create validation custom dataset\n","mnist_test = CustomImageTensorDataset(X_test, y_test, transform=validation_test_transform)     # create test custom dataset\n","\n","print(custom_mnist_train.__len__())\n","print(mnist_validation.__len__())\n","print(mnist_test.__len__())"]},{"cell_type":"markdown","metadata":{"id":"E0y9iJl_If7H"},"source":["### Training LeNet5 with data augmentation"]},{"cell_type":"code","source":["class LeNet5(nn.Module):\n","  def __init__(self):\n","    super(LeNet5, self).__init__()\n","    self.c1 = nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=2) # define a 2D convolutional layer\n","    self.s2 = nn.MaxPool2d(kernel_size=2, stride=2)               # define a maxpool layer\n","    self.c3 = nn.Conv2d(6, 16, kernel_size=5, stride=1)           # new 2D convolutional layer\n","    self.s4 = nn.MaxPool2d(kernel_size=2, stride=2)               # another maxpool layer\n","    self.c5 = nn.Linear(16*5*5, 120)                              # first linear layer\n","    self.f6 = nn.Linear(120, 84)                                  # second linear layer\n","    self.output = nn.Linear(84, 10)                               # final output layer\n","    self.act = nn.ReLU()                                          # activation function\n","    \n","  def forward(self, x):\n","    x = self.act(self.c1(x))                                      # activate pass through the first layer\n","    x = self.act(self.s2(x))                                      # activate pass through the second layer\n","    x = self.act(self.c3(x))                                      # activate pass through the third layer\n","    x = self.act(self.s4(x))                                      # activate pass through the fourth layer\n","    x = x.view(-1, x.size(1)*x.size(2)*x.size(3))                 # flatten (return a \"flattened\" view of the 3d tensor as inputs for the fully connected layer)\n","    x = self.act(self.c5(x))                                      # activate pass through fifth layer\n","    x = self.act(self.f6(x))                                      # activate pass through last layer\n","    return self.output(x)                                         # return output\n","  \n","x = torch.randn((1, 1, 28, 28))\n","model = LeNet5()\n","y = model(x)\n","print(y)\n","print(model)"],"metadata":{"id":"lRwa3fpoc67f"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w2YjquZWIf7H"},"outputs":[],"source":["def train_model_augmented(train_dataset, validation_dataset, momentum=0.5):\n","  set_seed(seed)\n","  model = LeNet5().to(device)\n","  optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n","  criterion = nn.CrossEntropyLoss()\n","  \n","  train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n","  validation_loader = DataLoader(validation_dataset, batch_size=test_batch_size, shuffle=False, num_workers=0)\n","\n","  liveloss = PlotLosses()\n","  for epoch in range(30):\n","      logs = {}\n","      train_loss, train_accuracy = train(model, optimizer, criterion, train_loader)\n","\n","      logs['' + 'log loss'] = train_loss.item()\n","      logs['' + 'accuracy'] = train_accuracy.item()\n","\n","      validation_loss, validation_accuracy = validate(model, criterion, validation_loader)\n","      logs['val_' + 'log loss'] = validation_loss.item()\n","      logs['val_' + 'accuracy'] = validation_accuracy.item()\n","\n","      liveloss.update(logs)\n","      liveloss.draw()\n","      \n","  return model\n","\n","model = train_model_augmented(custom_mnist_train, mnist_validation)"]},{"cell_type":"code","source":["validation_loader = DataLoader(mnist_validate, batch_size=test_batch_size, shuffle=False, num_workers=0) # create a validation_loader\n","y_pred, y_gt = evaluate(model, validation_loader) # generate predictions and ground truths by evaluating the model"],"metadata":{"id":"v4mqrRRnh68w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import ConfusionMatrixDisplay\n","\n","fig, ax = plt.subplots(figsize=(6,6))\n","ConfusionMatrixDisplay.from_predictions(y_gt, y_pred, ax=ax, colorbar=False, cmap='bone_r')\n","plt.show()"],"metadata":{"id":"101_0Wvph68w"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NHXp9ATcIf7I"},"source":["### Alternative implementation of the transforms\n","\n","We can also define transforms directly when we get MNIST from [`torchvision.datasets.MNIST`](https://pytorch.org/vision/stable/datasets.html#mnist)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ddkqUKHoIf7I"},"outputs":[],"source":["pretransform_mnist_train = MNIST(\"./\", download=True, train=True, transform=Compose([\n","    ### add your transforms here \n","\n","]))\n","\n","model = train_model_augmented(pretransform_mnist_train, mnist_validation)"]},{"cell_type":"code","source":["validation_loader = DataLoader(mnist_validate, batch_size=test_batch_size, shuffle=False, num_workers=0) # create a validation_loader\n","y_pred, y_gt = evaluate(model, validation_loader) # generate predictions and ground truths by evaluating the model"],"metadata":{"id":"uCOtWiojiEJn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import ConfusionMatrixDisplay\n","\n","fig, ax = plt.subplots(figsize=(6,6))\n","ConfusionMatrixDisplay.from_predictions(y_gt, y_pred, ax=ax, colorbar=False, cmap='bone_r')\n","plt.show()"],"metadata":{"id":"j5f242yWiEJo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["reference result from this morning plain Lenet-5 implementation for reference:\n","\n","<img src=\"https://drive.google.com/uc?id=1Q9dWZOCYKE_-looC8455K5hxEokZ7i5B\" width=\"600\"/>"],"metadata":{"id":"edbEiroVigoT"}}]}