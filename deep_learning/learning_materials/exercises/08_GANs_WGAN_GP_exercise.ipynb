{"cells":[{"cell_type":"markdown","metadata":{"id":"dy2ghzQMKGrz"},"source":["<img src=\"https://drive.google.com/uc?id=1dFgNX9iQUfmBOdmUN2-H8rPxL3SLXmxn\" width=\"400\"/>\n","\n","\n","---\n","\n","created by **Jiashun Yao**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LL3vQPYkhzOy","outputId":"d03fecab-1c9e-4415-918d-d5241ced861c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: livelossplot in /usr/local/lib/python3.7/dist-packages (0.5.5)\n","Requirement already satisfied: bokeh in /usr/local/lib/python3.7/dist-packages (from livelossplot) (2.3.3)\n","Requirement already satisfied: ipython==7.* in /usr/local/lib/python3.7/dist-packages (from livelossplot) (7.33.0)\n","Requirement already satisfied: numpy<1.22 in /usr/local/lib/python3.7/dist-packages (from livelossplot) (1.21.6)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from livelossplot) (3.2.2)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (2.6.1)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (0.7.5)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (0.2.0)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (57.4.0)\n","Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (0.18.1)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (5.1.1)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (0.1.3)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (3.0.29)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (4.8.0)\n","Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.16->ipython==7.*->livelossplot) (0.8.3)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect>4.3->ipython==7.*->livelossplot) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython==7.*->livelossplot) (0.2.5)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (2.8.2)\n","Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (3.13)\n","Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (21.3)\n","Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (5.1.1)\n","Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (4.2.0)\n","Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (2.11.3)\n","Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (7.1.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.9->bokeh->livelossplot) (2.0.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=16.8->bokeh->livelossplot) (3.0.8)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->bokeh->livelossplot) (1.15.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->livelossplot) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->livelossplot) (1.4.2)\n","Populating the interactive namespace from numpy and matplotlib\n"]}],"source":["!pip install livelossplot\n","%pylab inline"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pJpPlOgUlV77","outputId":"81fdcb7b-3877-4146-9969-3a2784d922ba"},"outputs":[{"name":"stdout","output_type":"stream","text":["Populating the interactive namespace from numpy and matplotlib\n"]}],"source":["%pylab inline"]},{"cell_type":"markdown","metadata":{"id":"En9dBOn0hzPL"},"source":["## Afternoon Session 6: Wasserstein Generative Adversarial Networks with Gradient Penalty (WGAN-GP)"]},{"cell_type":"markdown","metadata":{"id":"rGURJ5EBhzPO"},"source":["WGAN is a solution to the \"hard to train\" problem of GANs. Instead of optimising the J-S divergence between the $\\mathbb P_{data}$ and $\\mathbb P_G$, WGAN measures and optimises the \"***Wasserstein distance***\" between the two distributions.\n","\n","This simple change of the loss function brings excellent properties:\n","* training process is more stable\n","* the loss value is more \"meaningful\" as an indicator of the quality of the generated data\n","\n","![]()\n","\n","\n","\n","\n","<figure>\n","<center>\n","<img src='https://www.researchgate.net/profile/Soheil-Kolouri-2/publication/324246144/figure/fig6/AS:612260317777920@1522985643291/These-plots-show-W-1-p-q-t-and-JSp-q-t-where-p-is-a-uniform-distribution-around.png' />\n","<figcaption>These plots show W-distance and J-S divergence where p is a uniform distribution around zero and q τ (x) = p(x − τ). It is clear that JS divergence does not provide a usable gradient when distributions are supported on non-overlapping domains. (Kolouri et al, 2018)</figcaption></center> \n","</figure>"]},{"cell_type":"markdown","metadata":{"id":"dsfnolJPE1Ov"},"source":["### What is \"Wasserstein distance\":\n","* also called \"Earth mover distance\"\n","* Intuitively, imaging $\\mathbb P_{data}$ and $\\mathbb P_G$ to be two piles of soil, the Wasserstein distance is the minimum \"cost\" of moving one pile into the other."]},{"cell_type":"markdown","metadata":{"id":"ziULMUlvNFbV"},"source":["## Math of the WGAN-GP\n","By defination:\n","\n","$\\mathbf W(\\mathbb P_{data}, \\mathbb P_G) = \\inf_{\\gamma \\in \\Pi(\\mathbb P_{data}\\, , \\mathbb P_G)} \\mathbb E_{(x, x_G)\\sim \\gamma} [ \\| x - x_G \\| ] - (1)$\n","\n","Equation (1) says that:\n","1. from a joint distribution (of the real data and fake generated data) $\\gamma$, we can sample a pair of real data sample $x$ and a fake data sample $x_G = G(z)$;\n","2. the distance between the two samples are $\\| x - x_G \\|$;\n","3. when enough samples from $\\gamma$ are samples, we can estimate the expected value of the above distance under this joint distribution;\n","4. $\\mathbf W(\\mathbb P_{data}, \\mathbb P_G)$ is defined as the infimum of such expected values over all possible joint distributions.\n","\n","It is clear that this infimum is highly intractable -- we only have limited number of samples of $\\mathbb P_{data}$ and $\\mathbb P_G$.\n","\n","Alternatively, according to the Kantorovich-Rubinstein duality (Arjovsky et al 2017), equation (1) can be changed into:\n","\n","$\\mathbf W(\\mathbb P_{data}, \\mathbb P_G) = \\sup_{\\| f \\|_L \\le 1} \\mathbb E_{x \\sim \\mathbb P_{data} }[f(x)] - \\mathbb E_{x_G \\sim \\mathbb P_G }[f(x_G)] - (2)$\n","\n","where the supremum is over all the 1-Lipschitz functions f (i.e., the gradient norm $|f(x_1) - f(x_2)|/|x_1 - x_2| \\le 1$ for any pairs of ($x_1, x_2$).\n","\n","This duality is mportant because that such functions of $f$ in Equation (2) can be approximated using deep neural networks (our discriminator $D$), and the 1-Lipschitz requirement can be met during the training of $D$ using regularizations. The approximation of (2) can be written as (Gulrajani et al, 2017):\n","\n","$\\mathbf W(\\mathbb P_{data}, \\mathbb P_G) \\approx \\max \\{\\mathbb E_{x \\sim \\mathbb P_{data} }[D(x)] - \\mathbb E_{x_G \\sim \\mathbb P_G }[D(x_G)] - \\mu \\mathbb E_{\\hat x \\sim \\mathbb P_{\\hat x}}[(\\| \\nabla_\\hat{x} D(\\hat x)\\|_2 - 1]\\} - (3)$\n","\n","where the first two terms are simply from (2), but the newly added third term is to penalize the gradient norm (Gradient Penalty) to let it meet the 1-Lipschitz continuity requirement. $\\mu$ is a weightening factor for this term, $\\hat x$ is a random linear interpolation between $x$ and $x_G$: \n","\n","$\\hat x$ = $\\epsilon x + (1-\\epsilon x_G)$, where $\\epsilon \\sim U[0,1]$.\n","\n","Once the network has been trained, the gradient with respect to the generator can be found by differentiating (2) with respect to generator $G$:\n","\n","$\\nabla_G W(\\mathbb P_{data}, \\mathbb P_G) = -\\nabla_G D(G(z))$"]},{"cell_type":"markdown","metadata":{"id":"Qy6QVv6uXkf9"},"source":["## Algorithm of the WGAN-GP\n","<figure>\n","<center>\n","<img src='https://miro.medium.com/max/1400/1*JnBQNCOJxa8w9YMc5YjoXQ.png' />\n","<figcaption>(Gulrajani et al, 2017)</figcaption></center> \n","</figure>\n"]},{"cell_type":"markdown","metadata":{"id":"Q6xXe-1datp7"},"source":["For each training batch, this algorithm says below: \n","1. get m samples from real data ($x\\sim \\mathbb P_{data}$);\n","2. get m samples from the latent space ($z \\sim \\mathbb P_{z}$), input them into generater to generate m fake samples $x_G = G(z)$; Now we have m pairs real and fake data;\n","3. generate a random number $\\epsilon$ between 0 and 1 ($\\epsilon \\sim U[0,1]$);\n","4. compute m interpolated samples ($\\hat x$) from the paired real and fake data: $\\hat x = \\epsilon x + (1-\\epsilon)x_G$;\n","5. Construct the loss function for each paired data: $L = D(x_G) - D(x) + \\lambda(\\|\\nabla_{\\hat x} D(\\hat x)\\|_2 -1)^2$;\n","6. Train $D$ to minimise the loss for this batch $\\frac{1}{m}\\sum_{i=1}^m L^{i}$ (we flipped the sign of equation (3) so we do minimisation here);\n","7. Train $G$ to minimise $\\frac{1}{m} \\sum_{i=1}^m -D(G(z))$\n","\n","Note: \n","* $\\lambda$ - the weight of the gradient penalty term\n","* $n_{critic}$ - in each batch, run $n_{critic}$ iterations for adversarial network, and 1 iteration for generator network "]},{"cell_type":"markdown","metadata":{"id":"MXJ6R5CBhzPQ"},"source":["#### A few imports before we get started"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5-tUzUV2hzPU","outputId":"2f72e69c-adcc-4b39-a846-68c2119b9537"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cuda installed! Running on GPU!\n"]}],"source":["from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import StratifiedShuffleSplit\n","\n","from livelossplot import PlotLosses\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.autograd as autograd\n","from torch.autograd import Variable\n","from torch.utils.data import TensorDataset, DataLoader\n","import torchvision.transforms as transforms\n","from torchvision.datasets import MNIST\n","\n","import random \n","def set_seed(seed):\n","    \"\"\"\n","    Use this to set ALL the random seeds to a fixed value and take out any randomness from cuda kernels\n","    \"\"\"\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","\n","    torch.backends.cudnn.benchmark = False  ##uses the inbuilt cudnn auto-tuner to find the fastest convolution algorithms. -\n","    torch.backends.cudnn.enabled   = False\n","\n","    return True\n","\n","device = 'cpu'\n","if torch.cuda.device_count() > 0 and torch.cuda.is_available():\n","    print(\"Cuda installed! Running on GPU!\")\n","    device = 'cuda'\n","else:\n","    print(\"No GPU available!\")"]},{"cell_type":"markdown","metadata":{"id":"6tLRNHc8GOfR"},"source":["### Mounting the google drive for later storage"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dg3oP6GHGOsX","outputId":"99ef3729-d3f6-4f7c-e81e-9212b08638e4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive/')"]},{"cell_type":"markdown","metadata":{"id":"CEwibQeWjYQC"},"source":["### Exercise: Implementing the WGAN-GP\n","\n","In this session you will implement a WGAN-GP using the MNIST dataset.\n","\n","Latent vector length: 100\n","\n","Network G:\n","1. Layer 1: 100 -> 256 (100 is length of latent vector)\n","2. Layer 2: 256 -> 512\n","3. Layer 3: 512 -> 1024\n","4. Layer 4: 1024 -> 784 (size of a MNIST image)\n","\n","Apply leaky_relu(alpha=0.2) activation functions for layers 1-3, and tanh to layer 4.\n","* Leaky_relu helps to mitigate Vanishing gradient problem\n","\n","Network D:\n","1. Layer 1: 784 -> 1024 \n","2. Layer 2: 1024 -> 512 \n","3. Layer 3: 512 -> 256 \n","3. Layer 4: 256 -> 1\n","\n","\n","Apply leaky_relu(alpha=0.2) activation functions for layers 1-3, and ***no activation*** to layer 4. \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UYJMYuNItYp6"},"outputs":[],"source":["class Generator(nn.Module):\n","    def __init__(self, g_input_dim=100, g_output_dim=28*28):\n","        super().__init__()       \n","\n","    \n","    # forward method\n","    def forward(self, x): \n","\n","        return \n","    \n","class Discriminator(nn.Module):\n","    def __init__(self, d_input_dim=28*28):\n","        super().__init__()\n","\n","    \n","    # forward method\n","    def forward(self, x):\n","\n","        return \n","    \n","\n","# build model\n","G = Generator().to(device)\n","D = Discriminator().to(device)"]},{"cell_type":"markdown","metadata":{"id":"_yYNgVsIyWPZ"},"source":["Print $G$ and $D$"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZPVNu125Z3WD","outputId":"85ca2d35-f659-465a-cf41-3681651d3df5"},"outputs":[{"data":{"text/plain":["Generator(\n","  (fc1): Linear(in_features=100, out_features=256, bias=True)\n","  (fc2): Linear(in_features=256, out_features=512, bias=True)\n","  (fc3): Linear(in_features=512, out_features=1024, bias=True)\n","  (fc4): Linear(in_features=1024, out_features=784, bias=True)\n",")"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["G"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DA74OfAWZ_4i","outputId":"cf988c3e-01c8-4465-d328-f8e060b1021a"},"outputs":[{"data":{"text/plain":["Discriminator(\n","  (fc1): Linear(in_features=784, out_features=1024, bias=True)\n","  (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","  (fc3): Linear(in_features=512, out_features=256, bias=True)\n","  (fc4): Linear(in_features=256, out_features=1, bias=True)\n",")"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["D"]},{"cell_type":"markdown","metadata":{"id":"w0fK-Iq3FrC2"},"source":["Loss and hyper-parameters:\n","* batch_size = 100\n","* learning_rate = 0.0002\n","* Optimisor -- Adam\n","\n","* $\\lambda$ = 10\n","* $n_{critic}$ = 5"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3K-yVuQvhzPs"},"outputs":[],"source":["# define loss\n","criterion = nn.BCELoss() \n","z_dim = 100\n","bs = 100\n","lambda_gp = 10\n","n_critic = 5\n","\n","# optimizer\n","lr = 0.0002\n","G_optimizer = torch.optim.Adam(G.parameters(), lr = lr)\n","D_optimizer = torch.optim.Adam(D.parameters(), lr = lr)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gGjkclrdabiE"},"outputs":[],"source":["# MNIST Dataset\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=(0.5), std=(0.5))])\n","\n","train_dataset = MNIST(root='./mnist_data/', train=True, transform=transform, download=True)\n","\n","# Data Loader (Input Pipeline)\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=bs, shuffle=True)\n"]},{"cell_type":"markdown","metadata":{"id":"OCZFhre9Dkmd"},"source":["## The trainining:\n","\n","1. Train $D$, repeat for $n_{critic}$ iterations:\n","  * Sample $m$ latent samples $z$; and sample $m$ real data $x$\n","  * generate fake data $x_g = G(z)$\n","  * generate $\\hat x$\n","    * sample $\\epsilon \\sim U[0,1]$\n","    * $\\hat x = \\epsilon x + (1-\\epsilon) x_g$\n","  * construct the gradient penalty term $D_{gp} = (\\| \\nabla_{\\hat x} D(\\hat x) \\|_2 -1)^2$\n","  * construct the loss for $D$ training: $L_D = D(x_g) - D(x) +\\lambda D_{gp}$\n","  * update $D$ to minimise the loss $\\frac{1}{m}L$\n","   \n","2. Train $G$:\n","  * Sample $m$ latent samples $z$\n","  * generate the fake image $x_g = G(z)$\n","  * construct the loss for $G$ training: $L_G = -D(x_G)$\n","  * update $G$ to minimise the loss $\\frac{1}{m}L_G$"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3c2nq1jnbRs-"},"outputs":[],"source":["def gp_term(x_real, x_fake):\n","\n","    # epsilon \n","\n","\n","    # x_interp\n","\n","    # set x_interp to requires_grad to compute the grad norm\n","    x_interp = Variable(x_interp, requires_grad = True) \n","\n","    # D_interp\n","\n","\n","    # grad_interp\n","    grad_D_interp = autograd.grad(outputs = D_interp,\n","                 inputs = x_interp,\n","                 grad_outputs=torch.ones((bs, 1)).to(device),\n","                 create_graph=True, retain_graph=True, only_inputs=True)[0]\n","\n","    # D_gp term             \n","    D_gp = (grad_D_interp.norm(2, dim=1) - 1) ** 2\n","\n","    return D_gp"]},{"cell_type":"markdown","metadata":{"id":"iVHIsRSZgk1r"},"source":["### Define the trianing processes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"709RReKLgt5T"},"outputs":[],"source":["def D_train(x, lambda_gp):\n","    #-------------- Function of the discriminator training -------------------#\n","    D.train()\n","    D_optimizer.zero_grad()\n","\n","    # D_real \n","\n","\n","    # D_fake\n","    # sample vector and produce generator output\n","\n","\n","    # D_gp\n","    \n","    # combine the losses\n","\n","    # model update \n","\n","        \n","    return  D_loss.data.item()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PREiK4o6hYGM"},"outputs":[],"source":["def G_train(x):\n","    #-------------- Function of the generator training -------------------#\n","    G.train()\n","    G_optimizer.zero_grad()\n","    \n","    # sample vector and produce generator output\n","\n","\n","    # D_output for x_fake\n","\n","    # G loss\n","\n","    # model update \n","\n","        \n","    return G_loss.data.item()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X-gL2iF0aU_T"},"outputs":[],"source":["n_epoch = 200 # about 40 minutes\n","groups = {'Loss': ['D_Loss', 'G_Loss']}\n","liveloss = PlotLosses(groups=groups)\n","\n","for epoch in range(1, n_epoch+1):  \n","  D_losses, G_losses = [], []\n","  logs = {}\n","  \n","  for batch_idx, (x, _) in enumerate(train_loader):\n","    logs['D_Loss'] = D_train(x, lambda_gp) \n","    if (batch_idx % n_critic == 0):\n","      logs['G_Loss'] = G_train(x)\n","  liveloss.update(logs)\n","  liveloss.draw()\n","\n","  # save every 20th epochs\n","  if(np.mod(epoch, 20) == 0):\n","    torch.save(G.state_dict(), \"./Generator_{:03d}.pth\".format(epoch))"]},{"cell_type":"markdown","metadata":{"id":"2N5sFtRNIMbu"},"source":["### Sample random latent vectors, and input into generator to generate images."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MLP14wLPaVCU"},"outputs":[],"source":["# from torchvision.utils import save_image\n","set_seed(0)\n","\n","epoch = 20\n","G.load_state_dict(torch.load(\"./Generator_{:03d}.pth\".format(epoch)))\n","\n","\n","with torch.no_grad():\n","    test_z = Variable(torch.randn(bs, z_dim).to(device))\n","    generated = G(test_z)\n","\n","    # save_image(generated.view(generated.size(0), 1, 28, 28), './sample_' + '.png')\n","fig, axarr = plt.subplots(10, 10, figsize=(12, 12))\n","for ax, img in zip(axarr.flatten(), generated.view(generated.size(0), 28, 28).cpu()):\n","  ax.imshow(img, cmap=\"gray\")\n","plt.title('Epoch = {:03d}'.format(epoch))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VfoiiqxZaVHz"},"outputs":[],"source":["# from torchvision.utils import save_image\n","set_seed(0)\n","\n","epoch = 40\n","G.load_state_dict(torch.load(\"./Generator_{:03d}.pth\".format(epoch)))\n","\n","\n","with torch.no_grad():\n","    test_z = Variable(torch.randn(bs, z_dim).to(device))\n","    generated = G(test_z)\n","\n","    # save_image(generated.view(generated.size(0), 1, 28, 28), './sample_' + '.png')\n","fig, axarr = plt.subplots(10, 10, figsize=(12, 12))\n","for ax, img in zip(axarr.flatten(), generated.view(generated.size(0), 28, 28).cpu()):\n","  ax.imshow(img, cmap=\"gray\")\n","plt.title('Epoch = {:03d}'.format(epoch))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QHd6MxLUtxMs"},"outputs":[],"source":["# from torchvision.utils import save_image\n","set_seed(0)\n","\n","epoch = 140\n","G.load_state_dict(torch.load(\"./Generator_{:03d}.pth\".format(epoch)))\n","\n","\n","with torch.no_grad():\n","    test_z = Variable(torch.randn(bs, z_dim).to(device))\n","    generated = G(test_z)\n","\n","    # save_image(generated.view(generated.size(0), 1, 28, 28), './sample_' + '.png')\n","fig, axarr = plt.subplots(10, 10, figsize=(12, 12))\n","for ax, img in zip(axarr.flatten(), generated.view(generated.size(0), 28, 28).cpu()):\n","  ax.imshow(img, cmap=\"gray\")\n","plt.title('Epoch = {:03d}'.format(epoch))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MxLpHZ0PaVKs"},"outputs":[],"source":["# from torchvision.utils import save_image\n","set_seed(0)\n","\n","epoch = 200\n","G.load_state_dict(torch.load(\"./Generator_{:03d}.pth\".format(epoch)))\n","\n","\n","with torch.no_grad():\n","    test_z = Variable(torch.randn(bs, z_dim).to(device))\n","    generated = G(test_z)\n","\n","    # save_image(generated.view(generated.size(0), 1, 28, 28), './sample_' + '.png')\n","fig, axarr = plt.subplots(10, 10, figsize=(12, 12))\n","for ax, img in zip(axarr.flatten(), generated.view(generated.size(0), 28, 28).cpu()):\n","  ax.imshow(img, cmap=\"gray\")\n","plt.title('Epoch = {:03d}'.format(epoch))"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"https://github.com/ese-msc-2021/ML_module/blob/master/implementation/7_VAE_GAN/7_VAE_GAN_afternoon/Afternoon_Session_6_GANs_Exercise_WGAN_GP.ipynb","timestamp":1670157796547}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":0}